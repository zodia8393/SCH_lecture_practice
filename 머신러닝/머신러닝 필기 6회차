2022-03-28

과대적합과 정규화
  편향:전체 데이터샘플에 대한 차이의 정도
    -모델의 결과가 한쪽으로 치우쳐저있는 것
    -전체적인 값을 옮겨주기만 하면 해결할수있음
    
  분산:모델결과가 얼마나 퍼져있는지,차이값이 얼마나 퍼져있는지의 정도
  
편향은 같이 움직이는것, 분산은 골고루 퍼져있는것
편향과 분산은 트레이드오프관계이다 (편향이 높으면 분산이 낮고 분산이 높으면 편향이 낮음)

과대적합: 높은분산,낮은편향 상태, 함수가 훈련데이터셋에만 맞음,피쳐의 개수를 줄이거나 정규화하여 해결한다
괴소적합: 낮은분산,높은편향 상태, 훈련데이터셋과 테스트 데이터셋에 모두 맞지 않음, 피쳐를 추가하여 해결한다

과대적합 발생시 경사하강법 루프가 진행될수록 학습 데이터셋에 대한 비용함수값은 줄어들지만 테스트 데이터셋의 비용함수값은 증가한다

과대적합 극복하기
  오컴의 면도날 원리 : 보다 적은수의 논리로 설명가능한 경우 많은 수의 논리를 세우지 않는다
    -머신러닝에서는 너무 많은 피쳐를 사용하지 않는것
    
  선형회귀에서 과대적합 해결책
    오류없고 분포 다양한 데이터 많이 확보해서 사용하기
    피쳐 개수 줄이기 
    적절한 매개변수 선정
    정규화 적용
    
L2정규화(리지 회귀)
  놈(norm) : 좌표평면의 원점에서 점까지의 거리를 나타내어 벡터의 크기를 측정하는 기법
    • 𝑥는 하나의 벡터
    • L2 놈(L2 norm) : 벡터 각 원소들의 제곱합에 제곱근을 취함
  리지 회귀는 L2놈을 선형회귀의 비용함수 수식에 적용시킨다
  리지 회귀 수식을 미분하면 𝑗의 값이 1 이상일 때 페널티가 적용됨

L1정규화(라쏘 회귀)
  절대값을 다 더한것으로 패널티를 붙인다
  
L1 vs L2
L2는 제곱을 하고 L1은 절대값을 사용한다

  
  
    
